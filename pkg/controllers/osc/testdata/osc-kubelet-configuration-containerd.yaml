apiVersion: operatingsystemmanager.k8c.io/v1alpha1
kind: OperatingSystemConfig
metadata:
  annotations:
    k8c.io/machine-deployment-revision: "1"
  creationTimestamp: null
  name: kubelet-configuration-kube-system-config
  namespace: kube-system
  resourceVersion: "1"
spec:
  bootstrapConfig:
    files:
    - content:
        inline:
          data: |
            #!/bin/bash
            set -xeuo pipefail
            while ! "$@"; do
              sleep 1
            done
          encoding: b64
      path: /opt/bin/supervise.sh
      permissions: 755
    - content:
        inline:
          data: "#!/bin/bash\nset -xeuo pipefail\n\n# Check if bootstrap phase has
            already completed. This is required when we run `cloud-init init` again
            since it tries to re-run\n# the bootstrap cloud-config as well, from the
            userdata.\nif [ -f /etc/bootstrap-complete ]; then\n  exit 0\nfi\n\ncat
            <<EOF | tee -a /etc/environment\nHTTP_PROXY=http://test-http-proxy.com\nhttp_proxy=http://test-http-proxy.com\nHTTPS_PROXY=http://test-http-proxy.com\nhttps_proxy=http://test-http-proxy.com\nEOF\ncat
            <<EOF | tee -a /etc/environment\nNO_PROXY=http://test-no-proxy.com\nno_proxy=http://test-no-proxy.com\nEOF\n\nsudo
            mkdir -p /etc/apt/apt.conf.d\ncat <<EOF | sudo tee /etc/apt/apt.conf.d/proxy.conf\nAcquire::https::Proxy
            \"http://test-http-proxy.com\";\nAcquire::http::Proxy \"http://test-http-proxy.com\";\nEOF\n\nsource
            /etc/environment\n\nexport DEBIAN_FRONTEND=noninteractive\napt update
            && apt install -y curl jq\ncurl -s -k -v --header 'Authorization: Bearer
            top-secret'\thttps://foo.bar:6443/api/v1/namespaces/cloud-init-settings/secrets/kubelet-configuration-kube-system-provisioning-config
            | jq '.data[\"cloud-config\"]' -r| base64 -d > /etc/cloud/cloud.cfg.d/kubelet-configuration-kube-system-provisioning-config.cfg\ncloud-init
            clean\n\nCLOUD_INIT_VERSION=$(cloud-init --version | awk '{print $2}')\n#
            Compare the semver values of cloud-init versions to determine the correct
            command to run.\n# This is required because the command line arguments
            for cloud-init changed in version 24.1, for details: https://github.com/canonical/cloud-init/releases/tag/24.1.\nif
            [[ $(echo -e \"24.0.0\\n$CLOUD_INIT_VERSION\" | sort -V | head -n1) =
            \"24.0.0\" ]]; then\n    cloud-init init --file /etc/cloud/cloud.cfg.d/kubelet-configuration-kube-system-provisioning-config.cfg\nelse\n
            \   cloud-init --file /etc/cloud/cloud.cfg.d/kubelet-configuration-kube-system-provisioning-config.cfg
            init\nfi\n\nsystemctl daemon-reload\n\nsystemctl daemon-reload\n\n# cloud-init
            should only run on the first boot. From this point forward we don't need
            cloud-init anymore.\nsystemctl disable cloud-init\ntouch /etc/cloud/cloud-init.disabled\n\n#
            Bootstrap phase for the machine is complete.\ntouch /etc/bootstrap-complete\nsystemctl
            disable bootstrap.service\n\n# Start provisioning phase for the machine.\nsystemctl
            restart setup.service\n"
          encoding: b64
      path: /opt/bin/bootstrap
      permissions: 755
    - content:
        inline:
          data: |
            [Install]
            WantedBy=multi-user.target

            [Unit]
            Requires=network-online.target
            After=network-online.target
            [Service]
            Type=oneshot
            RemainAfterExit=true
            EnvironmentFile=-/etc/environment
            ExecStart=/opt/bin/supervise.sh /opt/bin/bootstrap
          encoding: b64
      path: /etc/systemd/system/bootstrap.service
      permissions: 644
    modules:
      runcmd:
      - systemctl restart bootstrap.service
      - systemctl daemon-reload
    userSSHKeys:
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDdOIhYmzCK5DSVLu3c
  cloudProvider:
    name: aws
    spec:
      availabilityZone: eu-central-1b
      subnetID: test-subnet
      vpcId: e-123f
  osName: ubuntu
  osVersion: "24.04"
  provisioningConfig:
    files:
    - content:
        inline:
          data: |
            #!/usr/bin/env bash

            # Copyright 2016 The Kubernetes Authors.
            #
            # Licensed under the Apache License, Version 2.0 (the "License");
            # you may not use this file except in compliance with the License.
            # You may obtain a copy of the License at
            #
            #     http://www.apache.org/licenses/LICENSE-2.0
            #
            # Unless required by applicable law or agreed to in writing, software
            # distributed under the License is distributed on an "AS IS" BASIS,
            # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
            # See the License for the specific language governing permissions and
            # limitations under the License.

            # This script is for master and node instance health monitoring, which is
            # packed in kube-manifest tarball. It is executed through a systemd service
            # in cluster/gce/gci/<master/node>.yaml. The env variables come from an env
            # file provided by the systemd service.

            # This script is a slightly adjusted version of
            # https://github.com/kubernetes/kubernetes/blob/e1a1aa211224fcd9b213420b80b2ae680669683d/cluster/gce/gci/health-monitor.sh
            # Adjustments are:
            # * Kubelet health port is 10248 not 10255
            # * Removal of all all references to the KUBE_ENV file

            set -o nounset
            set -o pipefail

            # We simply kill the process when there is a failure. Another systemd service will
            # automatically restart the process.
            function container_runtime_monitoring() {
              local -r max_attempts=5
              local attempt=1
              local -r container_runtime_name="${CONTAINER_RUNTIME_NAME:-docker}"
              # We still need to use 'docker ps' when container runtime is "docker". This is because
              # dockershim is still part of kubelet today. When kubelet is down, crictl pods
              # will also fail, and docker will be killed. This is undesirable especially when
              # docker live restore is disabled.
              local healthcheck_command="docker ps"
              if [[ "${CONTAINER_RUNTIME:-docker}" != "docker" ]]; then
                healthcheck_command="crictl pods"
              fi
              # Container runtime startup takes time. Make initial attempts before starting
              # killing the container runtime.
              until timeout 60 ${healthcheck_command} > /dev/null; do
                if ((attempt == max_attempts)); then
                  echo "Max attempt ${max_attempts} reached! Proceeding to monitor container runtime healthiness."
                  break
                fi
                echo "$attempt initial attempt \"${healthcheck_command}\"! Trying again in $attempt seconds..."
                sleep "$((2 ** attempt++))"
              done
              while true; do
                if ! timeout 60 ${healthcheck_command} > /dev/null; then
                  echo "Container runtime ${container_runtime_name} failed!"
                  if [[ "$container_runtime_name" == "docker" ]]; then
                    # Dump stack of docker daemon for investigation.
                    # Log file name looks like goroutine-stacks-TIMESTAMP and will be saved to
                    # the exec root directory, which is /var/run/docker/ on Ubuntu and COS.
                    pkill -SIGUSR1 dockerd
                  fi
                  systemctl kill --kill-who=main "${container_runtime_name}"
                  # Wait for a while, as we don't want to kill it again before it is really up.
                  sleep 120
                else
                  sleep "${SLEEP_SECONDS}"
                fi
              done
            }

            function kubelet_monitoring() {
              echo "Wait for 2 minutes for kubelet to be functional"
              sleep 120
              local -r max_seconds=10
              local output=""
              while true; do
                local failed=false

                if journalctl -u kubelet -n 1 | grep -q "use of closed network connection"; then
                  failed=true
                  echo "Kubelet stopped posting node status. Restarting"
                elif ! output=$(curl -m "${max_seconds}" -f -s -S http://127.0.0.1:10248/healthz 2>&1); then
                  failed=true
                  # Print the response and/or errors.
                  echo "$output"
                fi

                if [[ "$failed" == "true" ]]; then
                  echo "Kubelet is unhealthy!"
                  systemctl kill kubelet
                  # Wait for a while, as we don't want to kill it again before it is really up.
                  sleep 60
                else
                  sleep "${SLEEP_SECONDS}"
                fi
              done
            }

            ############## Main Function ################
            if [[ "$#" -ne 1 ]]; then
              echo "Usage: health-monitor.sh <container-runtime/kubelet>"
              exit 1
            fi

            SLEEP_SECONDS=10
            component=$1
            echo "Start kubernetes health monitoring for ${component}"
            if [[ "${component}" == "container-runtime" ]]; then
              container_runtime_monitoring
            elif [[ "${component}" == "kubelet" ]]; then
              kubelet_monitoring
            else
              echo "Health monitoring for component ${component} is not supported!"
            fi
          encoding: b64
      path: /opt/bin/health-monitor.sh
      permissions: 755
    - content:
        inline:
          data: |
            [Journal]
            SystemMaxUse=5G
          encoding: b64
      path: /etc/systemd/journald.conf.d/max_disk_use.conf
      permissions: 644
    - content:
        inline:
          data: |
            #!/usr/bin/env bash
            set -euo pipefail

            modprobe ip_vs
            modprobe ip_vs_rr
            modprobe ip_vs_wrr
            modprobe ip_vs_sh

            if modinfo nf_conntrack_ipv4 &> /dev/null; then
              modprobe nf_conntrack_ipv4
            else
              modprobe nf_conntrack
            fi
          encoding: b64
      path: /opt/load-kernel-modules.sh
      permissions: 755
    - content:
        inline:
          data: |
            net.bridge.bridge-nf-call-ip6tables = 1
            net.bridge.bridge-nf-call-iptables = 1
            kernel.panic_on_oops = 1
            kernel.panic = 10
            net.ipv4.ip_forward = 1
            vm.overcommit_memory = 1
            fs.inotify.max_user_watches = 1048576
            fs.inotify.max_user_instances = 8192
          encoding: b64
      path: /etc/sysctl.d/k8s.conf
      permissions: 644
    - content:
        inline:
          data: |
            # Added by kubermatic machine-controller
            # Enable cgroups memory and swap accounting
            GRUB_CMDLINE_LINUX="cgroup_enable=memory swapaccount=1"
          encoding: b64
      path: /etc/default/grub.d/60-swap-accounting.cfg
      permissions: 644
    - content:
        inline:
          data: |
            #!/bin/bash
            set -xeuo pipefail
            if systemctl is-active ufw; then systemctl stop ufw; fi
            systemctl mask ufw
            systemctl restart systemd-modules-load.service
            sysctl --system

            # Override hostname if /etc/machine-name exists
            if [ -x "$(command -v hostnamectl)" ] && [ -s /etc/machine-name ]; then
              machine_name=$(cat /etc/machine-name)
              hostnamectl set-hostname ${machine_name}
            fi

            apt-get update

            DEBIAN_FRONTEND=noninteractive apt-get -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" install -y \
              curl \
              ca-certificates \
              ceph-common \
              cifs-utils \
              conntrack \
              e2fsprogs \
              ebtables \
              ethtool \
              glusterfs-client \
              iptables \
              jq \
              kmod \
              openssh-client \
              nfs-common \
              socat \
              util-linux \
              ipvsadm
            apt-get update
            apt-get install -y apt-transport-https ca-certificates curl software-properties-common lsb-release
            install -m 0755 -d /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/$(lsb_release -si | tr '[:upper:]' '[:lower:]')/gpg | gpg --yes --dearmor -o /etc/apt/keyrings/docker.gpg
            echo "deb [signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/$(lsb_release -si | tr '[:upper:]' '[:lower:]') $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list

            apt-get update
            apt-get install -y --allow-downgrades -o Dpkg::Options::="--force-confold" containerd.io=1.7*
            apt-mark hold containerd.io

            systemctl daemon-reload
            systemctl enable --now containerd

            opt_bin=/opt/bin
            usr_local_bin=/usr/local/bin
            cni_bin_dir=/opt/cni/bin
            mkdir -p /etc/cni/net.d /etc/kubernetes/manifests "$opt_bin" "$cni_bin_dir"
            arch=${HOST_ARCH-}
            if [ -z "$arch" ]
            then
            case $(uname -m) in
            x86_64)
                arch="amd64"
                ;;
            aarch64)
                arch="arm64"
                ;;
            *)
                echo "unsupported CPU architecture, exiting"
                exit 1
                ;;
            esac
            fi
            CNI_VERSION="${CNI_VERSION:-v1.5.1}"
            cni_base_url="https://github.com/containernetworking/plugins/releases/download/$CNI_VERSION"
            cni_filename="cni-plugins-linux-$arch-$CNI_VERSION.tgz"
            curl -Lfo "$cni_bin_dir/$cni_filename" "$cni_base_url/$cni_filename"
            cni_sum=$(curl -Lf "$cni_base_url/$cni_filename.sha256")
            cd "$cni_bin_dir"
            sha256sum -c <<<"$cni_sum"
            tar xvf "$cni_filename"
            rm -f "$cni_filename"
            cd -
            chown -R root:root "$cni_bin_dir"
            CRI_TOOLS_RELEASE="v1.31.1"

            cri_tools_base_url="https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRI_TOOLS_RELEASE}"
            cri_tools_filename="crictl-${CRI_TOOLS_RELEASE}-linux-${arch}.tar.gz"
            curl -Lfo "$opt_bin/$cri_tools_filename" "$cri_tools_base_url/$cri_tools_filename"
            cri_tools_sum_value=$(curl -Lf "$cri_tools_base_url/$cri_tools_filename.sha256")
            cri_tools_sum="$cri_tools_sum_value $cri_tools_filename"
            cd "$opt_bin"
            sha256sum -c <<<"$cri_tools_sum"
            tar xvf "$cri_tools_filename"
            rm -f "$cri_tools_filename"
            ln -sf "$opt_bin/crictl" "$usr_local_bin"/crictl || echo "symbolic link is skipped"
            cd -
            KUBE_VERSION="${KUBE_VERSION:-v1.31.0}"
            kube_dir="$opt_bin/kubernetes-$KUBE_VERSION"
            kube_base_url="https://dl.k8s.io/$KUBE_VERSION/bin/linux/$arch"
            kube_sum_file="$kube_dir/sha256"
            mkdir -p "$kube_dir"
            : >"$kube_sum_file"

            for bin in kubelet kubeadm kubectl; do
                curl -Lfo "$kube_dir/$bin" "$kube_base_url/$bin"
                chmod +x "$kube_dir/$bin"
                sum=$(curl -Lf "$kube_base_url/$bin.sha256")
                echo "$sum  $kube_dir/$bin" >>"$kube_sum_file"
            done
            sha256sum -c "$kube_sum_file"

            for bin in kubelet kubeadm kubectl; do
                ln -sf "$kube_dir/$bin" "$opt_bin"/$bin
            done

            # set kubelet nodeip environment variable
            /opt/bin/setup_net_env.sh
            curl -s -k -v --header 'Authorization: Bearer top-secret' https://foo.bar:6443/api/v1/namespaces/cloud-init-settings/secrets/kube-system-kubelet-configuration-kubelet-bootstrap-config | jq '.data["kubeconfig"]' -r| base64 -d > /etc/kubernetes/bootstrap-kubelet.conf

            systemctl enable --now kubelet
            systemctl enable --now --no-block kubelet-healthcheck.service
            systemctl disable setup.service
          encoding: b64
      path: /opt/bin/setup
      permissions: 755
    - content:
        inline:
          data: |
            [Unit]
            After=containerd.service
            Requires=containerd.service

            Description=kubelet: The Kubernetes Node Agent
            Documentation=https://kubernetes.io/docs/home/

            [Service]
            User=root
            Restart=always
            StartLimitInterval=0
            RestartSec=10
            CPUAccounting=true
            MemoryAccounting=true

            Environment="PATH=/opt/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin/"
            EnvironmentFile=-/etc/environment

            ExecStartPre=/bin/bash /opt/disable-swap.sh
            ExecStartPre=/bin/bash /opt/load-kernel-modules.sh
            ExecStartPre=/bin/bash /opt/bin/setup_net_env.sh
            ExecStart=/opt/bin/kubelet \
              --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf \
              --kubeconfig=/var/lib/kubelet/kubeconfig \
              --config=/etc/kubernetes/kubelet.conf \
              --cert-dir=/etc/kubernetes/pki \
              --exit-on-lock-contention \
              --lock-file=/tmp/kubelet.lock \
              --container-runtime-endpoint=unix:///run/containerd/containerd.sock \
              --node-ip ${KUBELET_NODE_IP}

            [Install]
            WantedBy=multi-user.target
          encoding: b64
      path: /etc/systemd/system/kubelet.service
      permissions: 644
    - content:
        inline:
          data: |2+

          encoding: b64
      path: /etc/kubernetes/cloud-config
      permissions: 600
    - content:
        inline:
          data: |
            #!/usr/bin/env bash
            echodate() {
              echo "[$(date -Is)]" "$@"
            }

            # get the default interface IP address
            DEFAULT_IFC_IP=$(ip -o  route get 1 | grep -oP "src \K\S+")

            if [ -z "${DEFAULT_IFC_IP}" ]
            then
              echodate "Failed to get IP address for the default route interface"
              exit 1
            fi

            # get the full hostname
            FULL_HOSTNAME=$(hostname -f)
            # if /etc/machine-name is not empty then use the hostname from there
            if [ -s /etc/machine-name ]; then
              FULL_HOSTNAME=$(cat /etc/machine-name)
            fi

            # write the nodeip_env file
            # we need the line below because flatcar has the same string "coreos" in that file
            if grep -q coreos /etc/os-release
            then
              echo "KUBELET_NODE_IP=${DEFAULT_IFC_IP}\nKUBELET_HOSTNAME=${FULL_HOSTNAME}" > /etc/kubernetes/nodeip.conf
            else
              mkdir -p /etc/systemd/system/kubelet.service.d
              echo -e "[Service]\nEnvironment=\"KUBELET_NODE_IP=${DEFAULT_IFC_IP}\"\nEnvironment=\"KUBELET_HOSTNAME=${FULL_HOSTNAME}\"" > /etc/systemd/system/kubelet.service.d/nodeip.conf
            fi
          encoding: b64
      path: /opt/bin/setup_net_env.sh
      permissions: 755
    - content:
        inline:
          data: |
            -----BEGIN CERTIFICATE-----
            MIIEWjCCA0KgAwIBAgIJALfRlWsI8YQHMA0GCSqGSIb3DQEBBQUAMHsxCzAJBgNV
            BAYTAlVTMQswCQYDVQQIEwJDQTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEUMBIG
            A1UEChMLQnJhZGZpdHppbmMxEjAQBgNVBAMTCWxvY2FsaG9zdDEdMBsGCSqGSIb3
            DQEJARYOYnJhZEBkYW5nYS5jb20wHhcNMTQwNzE1MjA0NjA1WhcNMTcwNTA0MjA0
            NjA1WjB7MQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNhbiBG
            cmFuY2lzY28xFDASBgNVBAoTC0JyYWRmaXR6aW5jMRIwEAYDVQQDEwlsb2NhbGhv
            c3QxHTAbBgkqhkiG9w0BCQEWDmJyYWRAZGFuZ2EuY29tMIIBIjANBgkqhkiG9w0B
            AQEFAAOCAQ8AMIIBCgKCAQEAt5fAjp4fTcekWUTfzsp0kyih1OYbsGL0KX1eRbSS
            R8Od0+9Q62Hyny+GFwMTb4A/KU8mssoHvcceSAAbwfbxFK/+s51TobqUnORZrOoT
            ZjkUygbyXDSK99YBbcR1Pip8vwMTm4XKuLtCigeBBdjjAQdgUO28LENGlsMnmeYk
            JfODVGnVmr5Ltb9ANA8IKyTfsnHJ4iOCS/PlPbUj2q7YnoVLposUBMlgUb/CykX3
            mOoLb4yJJQyA/iST6ZxiIEj36D4yWZ5lg7YJl+UiiBQHGCnPdGyipqV06ex0heYW
            caiW8LWZSUQ93jQ+WVCH8hT7DQO1dmsvUmXlq/JeAlwQ/QIDAQABo4HgMIHdMB0G
            A1UdDgQWBBRcAROthS4P4U7vTfjByC569R7E6DCBrQYDVR0jBIGlMIGigBRcAROt
            hS4P4U7vTfjByC569R7E6KF/pH0wezELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAkNB
            MRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMRQwEgYDVQQKEwtCcmFkZml0emluYzES
            MBAGA1UEAxMJbG9jYWxob3N0MR0wGwYJKoZIhvcNAQkBFg5icmFkQGRhbmdhLmNv
            bYIJALfRlWsI8YQHMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBAG6h
            U9f9sNH0/6oBbGGy2EVU0UgITUQIrFWo9rFkrW5k/XkDjQm+3lzjT0iGR4IxE/Ao
            eU6sQhua7wrWeFEn47GL98lnCsJdD7oZNhFmQ95Tb/LnDUjs5Yj9brP0NWzXfYU4
            UK2ZnINJRcJpB8iRCaCxE8DdcUF0XqIEq6pA272snoLmiXLMvNl3kYEdm+je6voD
            58SNVEUsztzQyXmJEhCpwVI0A6QCjzXj+qvpmw3ZZHi8JwXei8ZZBLTSFBki8Z7n
            sH9BBH38/SzUmAN4QHSPy1gjqm00OAE8NaYDkh/bzE4d7mLGGMWp/WE3KPSu82HF
            kPe6XoSbiLm/kxk32T0=
            -----END CERTIFICATE-----
          encoding: b64
      path: /etc/kubernetes/pki/ca.crt
      permissions: 644
    - content:
        inline:
          data: |
            [Install]
            WantedBy=multi-user.target

            [Unit]
            Requires=network-online.target
            After=network-online.target

            [Service]
            Type=oneshot
            RemainAfterExit=true
            EnvironmentFile=-/etc/environment
            ExecStart=/opt/bin/supervise.sh /opt/bin/setup
          encoding: b64
      path: /etc/systemd/system/setup.service
      permissions: 644
    - content:
        inline:
          data: |
            export PATH="/opt/bin:$PATH"
          encoding: b64
      path: /etc/profile.d/opt-bin-path.sh
      permissions: 644
    - content:
        inline:
          data: |
            apiVersion: kubelet.config.k8s.io/v1beta1
            kind: KubeletConfiguration
            authentication:
              anonymous:
                enabled: false
              webhook:
                cacheTTL: 2m
                enabled: true
              x509:
                clientCAFile: /etc/kubernetes/pki/ca.crt
            authorization:
              mode: Webhook
              webhook:
                cacheAuthorizedTTL: 5m0s
                cacheUnauthorizedTTL: 30s
            cgroupDriver: systemd
            clusterDNS:
            - "10.0.0.0"
            clusterDomain: cluster.local
            containerLogMaxSize: 300Mi
            containerLogMaxFiles: 30
            featureGates:
              GracefulNodeShutdown: true
              IdentifyPodOS: false
            protectKernelDefaults: true
            readOnlyPort: 0
            rotateCertificates: true
            serverTLSBootstrap: true
            staticPodPath: /etc/kubernetes/manifests
            # Enable parallel image pulling.
            serializeImagePulls: false
            # Set max parallel image pulls to 10.
            maxParallelImagePulls: 10
            kubeReserved:
              cpu: 30m
              ephemeral-storage: 30Gi
            systemReserved:
              cpu: 30m
              ephemeral-storage: 30Gi
            evictionHard:
              memory.available: 30Mi
            maxPods: 110
            tlsCipherSuites:
            - TLS_AES_128_GCM_SHA256
            - TLS_AES_256_GCM_SHA384
            - TLS_CHACHA20_POLY1305_SHA256
            - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
            - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
            - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
            - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
            - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
            - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
            volumePluginDir: /var/lib/kubelet/volumeplugins
            resolvConf: /run/systemd/resolve/resolv.conf
          encoding: b64
      path: /etc/kubernetes/kubelet.conf
      permissions: 644
    - content:
        inline:
          data: |
            [Unit]
            Requires=kubelet.service
            After=kubelet.service

            [Service]
            EnvironmentFile=-/etc/environment
            ExecStart=/opt/bin/health-monitor.sh kubelet

            [Install]
            WantedBy=multi-user.target
          encoding: b64
      path: /etc/systemd/system/kubelet-healthcheck.service
      permissions: 644
    - content:
        inline:
          data: |
            #!/usr/bin/env bash
            set -euo pipefail

            # Make sure we always disable swap - Otherwise the kubelet won't start as for some cloud
            # providers swap gets enabled on reboot or after the setup script has finished executing.
            sed -i.orig '/.*swap.*/d' /etc/fstab
            swapoff -a
          encoding: b64
      path: /opt/disable-swap.sh
      permissions: 755
    - content:
        inline:
          data: |
            [Service]
            Restart=always
            EnvironmentFile=-/etc/environment
      path: /etc/systemd/system/containerd.service.d/environment.conf
      permissions: 644
    - content:
        inline:
          data: |
            runtime-endpoint: unix:///run/containerd/containerd.sock
      path: /etc/crictl.yaml
      permissions: 644
    - content:
        inline:
          data: |+
            version = 2

            [metrics]
            address = "127.0.0.1:1338"

            [plugins]
            [plugins."io.containerd.grpc.v1.cri"]
            sandbox_image = "192.168.100.100:5000/kubernetes/pause:v3.1"
            [plugins."io.containerd.grpc.v1.cri".containerd]
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
            runtime_type = "io.containerd.runc.v2"
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
            SystemdCgroup = true
            [plugins."io.containerd.grpc.v1.cri".registry]
            [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
            [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
            endpoint = ["https://registry.docker-cn.com"]
            [plugins."io.containerd.grpc.v1.cri".registry.configs]
            [plugins."io.containerd.grpc.v1.cri".registry.configs."10.0.0.1:5000"]
            [plugins."io.containerd.grpc.v1.cri".registry.configs."10.0.0.1:5000".tls]
            insecure_skip_verify = true
            [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.100.100:5000"]
            [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.100.100:5000".tls]
            insecure_skip_verify = true

          encoding: b64
      path: /etc/containerd/config.toml
      permissions: 600
    userSSHKeys:
    - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDdOIhYmzCK5DSVLu3c
  provisioningUtility: cloud-init
